{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import time\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import DBPS_TF_NN_util as d_util\n",
    "import SBPS_TF_NN_util as s_util\n",
    "import MH_TF_NN_util as mh_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with 20*20, 400 pics for each label (training), 100 pics for each label (testing)\n",
    "X_train = np.load('/home/user/chou/Py_BPSs_NN_TF/X_train.npy')\n",
    "X_test = np.load('/home/user/chou/Py_BPSs_NN_TF/X_test.npy')\n",
    "y_train = np.load('/home/user/chou/Py_BPSs_NN_TF/y_train.npy')\n",
    "y_test = np.load('/home/user/chou/Py_BPSs_NN_TF/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from keras, 28 * 28, each labels has different pics, check it below\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "want = [4,9]\n",
    "newX_train = x_train[np.in1d(y_train, want)]\n",
    "newY_train = y_train[np.in1d(y_train, want)]\n",
    "newX_test = x_test[np.in1d(y_test, want)]\n",
    "newY_test = y_test[np.in1d(y_test, want)]\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "newY_train_onehot = encoder.fit_transform(newY_train.reshape(-1, 1))\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "newY_test_onehot = encoder.fit_transform(newY_test.reshape(-1, 1))\n",
    "print(np.shape(newX_train))\n",
    "print(np.shape(newX_test))\n",
    "\n",
    "np.save('X_train_keras49', newX_train.reshape(len(newX_train), 28*28))\n",
    "np.save('Y_train_keras49', newY_train_onehot)\n",
    "np.save('X_test_keras49', newX_test.reshape(len(newX_test), 28*28))\n",
    "np.save('Y_test_keras49', newY_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11791, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(newX_train.reshape(len(newX_train), 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:0: 5923\n",
      "num:1: 6742\n",
      "num:2: 5958\n",
      "num:3: 6131\n",
      "num:4: 5842\n",
      "num:5: 5421\n",
      "num:6: 5918\n",
      "num:7: 6265\n",
      "num:8: 5851\n",
      "num:9: 5949\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    want = [i]\n",
    "    a = sum(np.in1d(y_train, want))\n",
    "    print('num:' +str(i) + ': '+ str(a))\n",
    "    total += a\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num:0: 980\n",
      "num:1: 1135\n",
      "num:2: 1032\n",
      "num:3: 1010\n",
      "num:4: 982\n",
      "num:5: 892\n",
      "num:6: 958\n",
      "num:7: 1028\n",
      "num:8: 974\n",
      "num:9: 1009\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    want = [i]\n",
    "    a = sum(np.in1d(y_test, want))\n",
    "    print('num:' +str(i) + ': '+ str(a))\n",
    "    total += a\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras data set load\n",
    "X_train = np.load('/home/user/chou/Py_BPSs_NN_TF/X_train_keras49.npy')\n",
    "X_test = np.load('/home/user/chou/Py_BPSs_NN_TF/X_test_keras49.npy')\n",
    "y_train = np.load('/home/user/chou/Py_BPSs_NN_TF/Y_train_keras49.npy')\n",
    "y_test = np.load('/home/user/chou/Py_BPSs_NN_TF/Y_test_keras49.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11791, 784)\n",
      "(1991, 784)\n",
      "(11791, 2)\n",
      "(1991, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "Every settings are similar to Bayesian Logistic Regression, check BLR_simulation.ipynb for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_skip = 100\n",
    "iterations = 1e07\n",
    "verbose = 1e04\n",
    "save_iter = 10000\n",
    "burninIters = iterations /10 * 3\n",
    "\n",
    "MH_settings = []\n",
    "BPS_settings = []\n",
    "SBPS_settings = []\n",
    "DBPS_settings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current clock: 0.18308024466182174\n",
      "Current counts: 10000\n",
      "Current clock: 0.23759932573145792\n",
      "Current counts: 20000\n",
      "Current clock: 0.25493086930559\n",
      "Current counts: 30000\n",
      "Current clock: 0.28802619457093037\n",
      "Current counts: 40000\n",
      "Current clock: 0.3178923745958832\n",
      "Current counts: 50000\n",
      "Current clock: 0.3620578028998632\n",
      "Current counts: 60000\n",
      "Current clock: 0.38574251674294624\n",
      "Current counts: 70000\n",
      "Current clock: 0.45336423026757666\n",
      "Current counts: 80000\n",
      "Current clock: 0.5005491960544247\n",
      "Current counts: 90000\n",
      "Current clock: 0.5466468523951702\n",
      "Current counts: 100000\n",
      "Current clock: 0.5759937249335271\n",
      "Current counts: 110000\n",
      "Current clock: 0.6038659058667135\n",
      "Current counts: 120000\n",
      "Current clock: 0.6199034940591363\n",
      "Current counts: 130000\n",
      "Current clock: 0.6792161902606929\n",
      "Current counts: 140000\n",
      "Current clock: 0.6911706865856124\n",
      "Current counts: 150000\n",
      "Current clock: 0.7753529352399439\n",
      "Current counts: 160000\n",
      "Current clock: 0.8564776617692564\n",
      "Current counts: 170000\n",
      "Current clock: 0.9032564457551319\n",
      "Current counts: 180000\n",
      "Current clock: 0.917588408698638\n",
      "Current counts: 190000\n",
      "Current clock: 0.9622753959756359\n",
      "Current counts: 200000\n",
      "Current clock: 1.0323934305028744\n",
      "Current counts: 210000\n",
      "Current clock: 1.0411404811118172\n",
      "Current counts: 220000\n",
      "Current clock: 1.0475074948209748\n",
      "Current counts: 230000\n",
      "Current clock: 1.0543718793954786\n",
      "Current counts: 240000\n",
      "Current clock: 1.059447954895465\n",
      "Current counts: 250000\n",
      "Current clock: 1.065320298631701\n",
      "Current counts: 260000\n",
      "Current clock: 1.0733196270593284\n",
      "Current counts: 270000\n",
      "Current clock: 1.1360003626927446\n",
      "Current counts: 280000\n",
      "Current clock: 1.2241563324475917\n",
      "Current counts: 290000\n",
      "Current clock: 1.2662352491475353\n",
      "Current counts: 300000\n",
      "Current clock: 1.3449537708031774\n",
      "Current counts: 310000\n",
      "Current clock: 1.4583212365488838\n",
      "Current counts: 320000\n",
      "Current clock: 1.5367107439661296\n",
      "Current counts: 330000\n",
      "Current clock: 1.5654404921316585\n",
      "Current counts: 340000\n",
      "Current clock: 1.5864108544902764\n",
      "Current counts: 350000\n",
      "Current clock: 1.6753780892155925\n",
      "Current counts: 360000\n",
      "Current clock: 1.7331125728800199\n",
      "Current counts: 370000\n",
      "Current clock: 1.8404505163616862\n",
      "Current counts: 380000\n",
      "Current clock: 1.8983264516522638\n",
      "Current counts: 390000\n",
      "Current clock: 2.003376839205952\n",
      "Current counts: 400000\n",
      "Current clock: 2.10133906286225\n",
      "Current counts: 410000\n",
      "Current clock: 2.1815076914757743\n",
      "Current counts: 420000\n",
      "Current clock: 2.2103924370054964\n",
      "Current counts: 430000\n",
      "Current clock: 2.4517215214654517\n",
      "Current counts: 440000\n",
      "Current clock: 2.5901884772867714\n",
      "Current counts: 450000\n",
      "Current clock: 2.6656496380697408\n",
      "Current counts: 460000\n",
      "Current clock: 2.7315593521459816\n",
      "Current counts: 470000\n",
      "Current clock: 2.746638741617198\n",
      "Current counts: 480000\n",
      "Current clock: 2.764693801378054\n",
      "Current counts: 490000\n",
      "Current clock: 2.9893087890473797\n",
      "Current counts: 500000\n",
      "Current clock: 3.206769039381898\n",
      "Current counts: 510000\n",
      "Current clock: 3.4023928064992037\n",
      "Current counts: 520000\n",
      "Current clock: 3.6299032412618777\n",
      "Current counts: 530000\n",
      "Current clock: 3.660859606006323\n",
      "Current counts: 540000\n",
      "Current clock: 3.7397844054768985\n",
      "Current counts: 550000\n",
      "Current clock: 3.8430455396038434\n",
      "Current counts: 560000\n",
      "Current clock: 3.9806260302443857\n",
      "Current counts: 570000\n",
      "Current clock: 4.011787971629388\n",
      "Current counts: 580000\n",
      "Current clock: 4.092319019030991\n",
      "Current counts: 590000\n",
      "Current clock: 4.203001778855898\n",
      "Current counts: 600000\n",
      "Current clock: 4.251382983544638\n",
      "Current counts: 610000\n",
      "Current clock: 4.354527407015479\n",
      "Current counts: 620000\n",
      "Current clock: 4.429820151162032\n",
      "Current counts: 630000\n",
      "Current clock: 4.537288312788181\n",
      "Current counts: 640000\n",
      "Current clock: 4.552419740941616\n",
      "Current counts: 650000\n",
      "Current clock: 4.60196948484375\n",
      "Current counts: 660000\n",
      "Current clock: 4.640470364453765\n",
      "Current counts: 670000\n",
      "Current clock: 4.766453724885332\n",
      "Current counts: 680000\n",
      "Current clock: 4.878713934303336\n",
      "Current counts: 690000\n",
      "Current clock: 4.978467933419933\n",
      "Current counts: 700000\n",
      "Current clock: 5.060013713264824\n",
      "Current counts: 710000\n",
      "Current clock: 5.07751859000334\n",
      "Current counts: 720000\n",
      "Current clock: 5.180990794622325\n",
      "Current counts: 730000\n",
      "Current clock: 5.2609238624383154\n",
      "Current counts: 740000\n",
      "Current clock: 5.39769961307895\n",
      "Current counts: 750000\n",
      "Current clock: 5.53541995315819\n",
      "Current counts: 760000\n",
      "Current clock: 5.6195286761158725\n",
      "Current counts: 770000\n",
      "Current clock: 5.645891321985957\n",
      "Current counts: 780000\n",
      "Current clock: 5.662168014820228\n",
      "Current counts: 790000\n",
      "Current clock: 5.715374304546236\n",
      "Current counts: 800000\n",
      "Current clock: 5.830821772035664\n",
      "Current counts: 810000\n",
      "Current clock: 5.966498495667457\n",
      "Current counts: 820000\n",
      "Current clock: 6.115884397375968\n",
      "Current counts: 830000\n",
      "Current clock: 6.298261101394313\n",
      "Current counts: 840000\n",
      "Current clock: 6.418417039081491\n",
      "Current counts: 850000\n",
      "Current clock: 6.668569136177264\n",
      "Current counts: 860000\n",
      "Current clock: 6.8054440184858125\n",
      "Current counts: 870000\n",
      "Current clock: 6.972605560577337\n",
      "Current counts: 880000\n",
      "Current clock: 7.12238660205298\n",
      "Current counts: 890000\n",
      "Current clock: 7.231007761000952\n",
      "Current counts: 900000\n",
      "Current clock: 7.348281647114607\n",
      "Current counts: 910000\n",
      "Current clock: 7.488539367353759\n",
      "Current counts: 920000\n",
      "Current clock: 7.617541402164676\n",
      "Current counts: 930000\n",
      "Current clock: 7.802878751488258\n",
      "Current counts: 940000\n",
      "Current clock: 7.917216347488273\n",
      "Current counts: 950000\n",
      "Current clock: 7.935172698367123\n",
      "Current counts: 960000\n",
      "Current clock: 8.081875714627735\n",
      "Current counts: 970000\n",
      "Current clock: 8.101045244402318\n",
      "Current counts: 980000\n",
      "Current clock: 8.243998093935872\n",
      "Current counts: 990000\n",
      "Current clock: 8.284509610023653\n",
      "Current counts: 1000000\n",
      "Current clock: 8.461662663544852\n",
      "Current counts: 1010000\n",
      "Current clock: 8.712131315062747\n",
      "Current counts: 1020000\n",
      "Current clock: 9.01731469593963\n",
      "Current counts: 1030000\n",
      "Current clock: 9.271019328266323\n",
      "Current counts: 1040000\n",
      "Current clock: 9.587911989865901\n",
      "Current counts: 1050000\n",
      "Current clock: 9.714382209148248\n",
      "Current counts: 1060000\n",
      "Current clock: 9.934330877940798\n",
      "Current counts: 1070000\n",
      "Part: 1 saved\n",
      "Current clock: 10.150866628671922\n",
      "Current counts: 1080000\n",
      "Current clock: 10.2970717178696\n",
      "Current counts: 1090000\n",
      "Current clock: 10.385106857041174\n",
      "Current counts: 1100000\n"
     ]
    }
   ],
   "source": [
    "# ======\n",
    "# don't forget to fix the input_size in SBPS_util.py and DBPS_util.py correspond to the input size of the data set\n",
    "# ======\n",
    "# DBPS_settings.append([runtime, totaltime, NN_DBPS.burnin_sample, NN_DBPS.stage1_prob, NN_DBPS.stage2_prob])\n",
    "# SBPS_settings.append([runtime, totaltime, NN_SBPS.burnin_sample, NN_SBPS.after_burnin_storage_time, NN_SBPS.all_storage_time, NN_SBPS.theta_prior_bounce_count, NN_SBPS.bias_prior_bounce_count, NN_SBPS.likelihood_bounce_count])\n",
    "# MH_settings.append([runtime, totaltime, NN_MH.burnin_sample, NN_MH.accept_count])\n",
    "\n",
    "# DBPS\n",
    "subset = 0\n",
    "sto = 0\n",
    "k = np.array([-2], dtype = 'f')\n",
    "d = np.array([-2], dtype = 'f')\n",
    "kappa = 10**k\n",
    "delta = 10**d\n",
    "a = time.time()\n",
    "NN_DBPS = d_util.DBPS(X_train, y_train, delta, store_skip, save_iter)\n",
    "NN_DBPS.DBPS_sampler(iterations, burninIters, verbose, kappa, subset , sto)\n",
    "b = time.time()\n",
    "runtime = b-NN_DBPS.burnin_time\n",
    "totaltime = b-a\n",
    "DBPS_settings.append([runtime, totaltime, NN_DBPS.burnin_sample, NN_DBPS.stage1_prob, NN_DBPS.stage2_prob])\n",
    "del NN_DBPS\n",
    "gc.collect()\n",
    "\n",
    "np.save('DBPSsetting', np.array(DBPS_settings))\n",
    "\n",
    "# SBPS\n",
    "T = 10000\n",
    "dt = 1\n",
    "variance = 1\n",
    "mini_batch = 500\n",
    "ref = 10\n",
    "sample_time = 1e-03\n",
    "\n",
    "a = time.time()\n",
    "NN_SBPS = s_util.SBPS(X_train, y_train, T, dt, variance, mini_batch, save_iter)\n",
    "NN_SBPS.SBPS_sampler(ref, sample_time, iterations, burninIters, verbose)\n",
    "b = time.time()\n",
    "runtime = b-NN_SBPS.burnin_time\n",
    "totaltime = b-a\n",
    "SBPS_settings.append([runtime, totaltime, NN_SBPS.burnin_sample, NN_SBPS.after_burnin_storage_time, NN_SBPS.all_storage_time, NN_SBPS.theta_prior_bounce_count, NN_SBPS.bias_prior_bounce_count, NN_SBPS.likelihood_bounce_count, NN_SBPS.ref_count])\n",
    "del NN_SBPS\n",
    "gc.collect()\n",
    "np.save('SBPSsetting', np.array(SBPS_settings))\n",
    "\n",
    "# BPS\n",
    "T = 1000000\n",
    "dt = 1\n",
    "variance = 1\n",
    "mini_batch = len(X_train)\n",
    "ref = 10\n",
    "sample_time = 1e-03\n",
    "\n",
    "a = time.time()\n",
    "NN_SBPS = s_util.SBPS(X_train, y_train, T, dt, variance, mini_batch, save_iter)\n",
    "NN_SBPS.SBPS_sampler(ref, sample_time, iterations, burninIters, verbose)\n",
    "b = time.time()\n",
    "runtime = b-NN_SBPS.burnin_time\n",
    "totaltime = b-a\n",
    "BPS_settings.append([runtime, totaltime, NN_SBPS.burnin_sample, NN_SBPS.after_burnin_storage_time, NN_SBPS.all_storage_time, NN_SBPS.theta_prior_bounce_count, NN_SBPS.bias_prior_bounce_count, NN_SBPS.likelihood_bounce_count, NN_SBPS.ref_count])\n",
    "del NN_SBPS\n",
    "gc.collect()\n",
    "\n",
    "np.save('BPSsetting', np.array(BPS_settings))\n",
    "\n",
    "# MH\n",
    "can_sd = 0.5\n",
    "a = time.time()\n",
    "NN_MH = mh_util.MH(X_train, y_train,store_skip)\n",
    "NN_MH.MH_sampler(can_sd, burninIters, iterations, verbose, save_iter)\n",
    "b = time.time()\n",
    "runtime = b-NN_MH.burnin_time\n",
    "totaltime = b-a\n",
    "MH_settings.append([runtime, totaltime, NN_MH.burnin_sample, NN_MH.accept_count])\n",
    "del NN_MH\n",
    "gc.collect()\n",
    "\n",
    "np.save('MHsetting', np.array(MH_settings))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
